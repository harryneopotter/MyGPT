# Implementation Plan (Phased, Checklist-Gated)

This plan operationalizes `final_prd_logical_low_friction_ai_chat_system.md`. Each phase is a **hard gate**: do not start the next phase until every checklist item is satisfied.

> **PRD Supremacy Clause:** In any ambiguity or conflict, the FINAL PRD – Logical, Low-Friction AI Chat System governs. Interpretations that improve comfort, UX, performance, or developer convenience at the expense of intent supremacy, causal integrity, or inspectability are forbidden.

## Global Guardrails (Applies to Every Phase)
- **Never** edit or delete user messages; all “corrections” are appended messages that reference prior ones.
- **UI never talks to models.** Only the backend/control plane can call model servers.
- **No silent state changes.** Every persisted change ties back to a user message, an approved preference change, or an explicit user-triggered tool action.
- If you think you must deviate from the PRD, follow `docs/deviation-policy.md`.

## Phase Gate Evidence (Required for Each Phase)
For every phase, produce objective evidence (commit/PR artifacts) that a reviewer can verify quickly:
- A short demo note: “How to run” + “What to click/type” + expected result.
- A small set of copy/paste verification commands (backend health checks, DB checks, grep checks).
- If tests exist, a single command that runs them all and passes.

---

## Phase 0 — Repo & Toolchain Baseline
**Goal:** Establish a runnable skeleton with repeatable commands and “first-run” documentation.

**Deliverables**
- `README.md` with prerequisites (Windows 11, Python 3.11+, Node, Rust toolchain for Tauri) and exact run steps.
- Deterministic dependency management (lockfiles) for UI and backend.

**Checklist (Pass/Fail)**
- [ ] A single command starts backend in dev mode (e.g., `python -m uvicorn ...`).
- [ ] A single command starts UI in dev mode (e.g., `npm run tauri dev`).
- [ ] No network access required for core local operation (optional cloud explicitly off by default).

**Success Criteria**
- Fresh machine setup succeeds by following `README.md` verbatim with no “guessing”.

**Verification (Examples)**
- `python --version` shows 3.11+
- `node --version` prints successfully

---

## Phase 1 — Control Plane + UI Shell (No Models Yet)
**Goal:** Enforce architecture boundaries early: UI ↔ backend only.

**Deliverables**
- Backend: FastAPI app with health endpoint and WebSocket/SSE scaffold.
- UI: Tauri + React/TS app that renders a chat transcript and sends messages to backend.

**Checklist (Pass/Fail)**
- [ ] UI calls only backend endpoints (no direct calls to any model server URLs).
- [ ] Backend exposes a single base URL for UI (dev + prod config).
- [ ] Streaming path exists end-to-end (UI can render incremental tokens from a dummy generator).

**Success Criteria**
- Typing a message shows a streaming assistant response generated by backend stub logic.

**Verification (Examples)**
- `curl http://127.0.0.1:8000/health` returns OK
- UI shows incremental tokens (not a single “all-at-once” blob)

---

## Phase 2 — Immutable Message Log (SQLite) + Rendering
**Goal:** Make message integrity real: append-only storage and consistent rendering.

**Deliverables**
- SQLite schema for messages (append-only) and minimal migrations.
- Backend endpoints: create message, list conversation messages, stream assistant message.
- UI: transcript view that rehydrates from SQLite via backend.

**Checklist (Pass/Fail)**
- [ ] No code path updates or deletes message rows (no “edit message” feature).
- [ ] “Correction” is implemented as a new message referencing a prior message (e.g., `corrects_message_id`).
- [ ] Backend treats stored messages as historical facts when assembling prompts.
- [ ] SQLite enforces immutability with triggers that `RAISE(ABORT, ...)` on `UPDATE`/`DELETE` for message rows.

**Success Criteria**
- Restarting the app preserves the exact transcript (same ordering, same content).
- Any correction appears as a new message; the original remains unchanged.

**Verification (Examples)**
- Attempting `UPDATE messages SET ...` fails with the trigger error.
- Attempting `DELETE FROM messages ...` fails with the trigger error.

---

## Phase 3 — Model Gateway + Streaming (Local Models First)
**Goal:** Add model integration behind a single backend abstraction with robust streaming.

**Deliverables**
- Backend “model gateway” interface: `generate()`, `embed()`, `vision()` (even if some are stubbed initially).
- Local model integration via HTTP (e.g., llama.cpp server).
- Unified streaming adapter (SSE or WebSocket), including cancel/stop support.

**Checklist (Pass/Fail)**
- [ ] UI still does not talk to model servers (only backend).
- [ ] Backend can stream tokens and handle cancel cleanly (no partial DB corruption).
- [ ] Prompt assembly is deterministic and traceable (log request IDs + inputs, excluding secrets).

**Success Criteria**
- A real local model produces streaming responses with consistent stop/cancel behavior.

**Verification (Examples)**
- Cancel mid-stream leaves a well-formed transcript (no half-written DB rows).
- Switching model endpoints changes only backend configuration, not UI code.

---

## Phase 4 — Preference Inference Pipeline (Infer → Propose → Approve)
**Goal:** Implement preference inference without violating intent supremacy or creating hidden state.

**Deliverables**
- Storage separation: inferred proposals vs approved preferences.
- UI component for **one-at-a-time** preference proposal, visually secondary, shown **after** answers.
- Backend logic to apply only **approved** preferences as defaults (never as authority).

**Checklist (Pass/Fail)**
- [ ] Inferred preferences do **not** alter behavior until approved (PRD §3.2).
- [ ] Verified that inferred-but-unapproved preferences produce identical reasoning, framing, defaults, and outputs as baseline behavior.
- [ ] Verified that no preference inference alters question selection or response structure prior to approval.
- [ ] At most one proposal surfaces at a time (PRD §4).
- [ ] Proposals never appear before an answer and never interrupt streaming (PRD §5).
- [ ] Explicit user intent overrides preferences in every code path (PRD §2.2).
- [ ] Preference approvals are stored as explicit events (who/what/when), not implicit flags.

**Success Criteria**
- With identical user intent, behavior is the same whether a preference was inferred or not.
- After approval, defaults change in predictable ways that can be explained on request.

**Verification (Examples)**
- Clearing approved preferences returns behavior to baseline without changing message history.
- A “preference proposal” is visibly secondary and appears only after the answer.

---

## Phase 5 — Questioning Rules + Regeneration Semantics
**Goal:** Prevent “UX drift” into permission-seeking or hidden rethink behavior.

**Deliverables**
- Clarifying-question gate: only ask when answers materially change scope/inference (PRD §6).
- Regeneration implementation that is a true retry (PRD §7).

**Checklist (Pass/Fail)**
- [ ] No validation/permission-seeking questions (“Do you want me to…?”) unless user asked for options.
- [ ] Regenerate does not create new preference proposals or reset existing approved preferences.
- [ ] Regenerate does not silently change stored past messages.

**Success Criteria**
- Repeated regenerations yield alternative phrasings/attempts without altering state machines or preferences.

**Verification (Examples)**
- After 5 regenerations, `preferences` and approvals are unchanged unless the user explicitly changed them.
- No “are you sure” style prompts appear unless explicitly requested by the user.

---

## Phase 6 — Tool Execution Sandbox (Structured, Inspectable)
**Goal:** Safe, deterministic tool execution without giving the model a raw shell.

**Deliverables**
- Tool runner: subprocess isolation, explicit allowlist, structured JSON I/O only (PRD §13.9).
- Audit logs for tool runs (inputs, outputs, exit codes, timestamps, linked to causal message).

**Checklist (Pass/Fail)**
- [ ] No “direct shell exposure by default” (no arbitrary command execution from the model).
- [ ] Every tool run is user-triggered and attributable to a specific message.
- [ ] Verified that tools execute only as a direct, immediate consequence of a specific user message and never via chaining, scheduling, background execution, or speculative prefetch.
- [ ] Tool outputs are stored/attached as artifacts without mutating message history.

**Success Criteria**
- A tool can be executed, inspected, and replayed deterministically from stored inputs.

**Verification (Examples)**
- Attempting to run a non-allowlisted tool fails with a clear, structured error.
- A tool run produces a stored record with input JSON, output JSON, and exit status.

---

## Phase 7 — Performance, Packaging, and No-Background-Agents Guarantee
**Goal:** Meet constraints and prevent unintended autonomy.

**Deliverables**
- Startup and memory measurements documented; optimizations applied.
- Production packaging via Tauri; backend bundled or installed locally with clear path.

**Checklist (Pass/Fail)**
- [ ] Startup time target is met (PRD §13.10) or an explicit issue documents the gap + plan.
- [ ] No background autonomous agents; everything is user-triggered (PRD §13.11).
- [ ] Verified that no tool, model, or subsystem performs work without an explicit user-triggered message in the active session.
- [ ] Optional cloud paths are explicit, gated, and never required for local operation (PRD §13.5).

**Success Criteria**
- App launches quickly, stays idle without doing work, and remains fully usable offline with local models.

**Verification (Examples)**
- With the app idle, no periodic background requests occur and CPU stays near zero.
- All core flows work with network disabled (local model only).
